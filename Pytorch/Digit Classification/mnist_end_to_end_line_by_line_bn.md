ржмрзБржЭрзЗржЫрж┐ ЁЯЩВ тАФ рждрзБржорж┐ ржпрзЗржоржи **training loop**тАУржПрж░ ржЬржирзНржп рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ, ржЦрзБржБржЯрж┐ржирж╛ржЯрж┐ ржмрзНржпрж╛ржЦрзНржпрж╛ ржЪрзЗрзЯрзЗржЫрж┐рж▓рзЗ, **ржПржХржЗ рж╕рзНржЯрж╛ржЗрж▓рзЗ ржкрзБрж░рзЛ рж╕рзНржХрзНрж░рж┐ржкрзНржЯрзЗрж░ рж╕ржм ржмрзНрж▓ржХ** (рззтАУрзо) рж╕рж╛ржЬрж┐рзЯрзЗ ржжрж┐рж▓рж╛ржоред
ржПржЯрж╛ ржХржкрж┐ ржХрж░рзЗ GitHub-ржП рж░рж╛ржЦрждрзЗ ржкрж╛рж░рзЛред

> **GitHub ржлрж╛ржЗрж▓ ржирж╛ржо (рж╕рж╛ржЬрзЗрж╕рзНржЯрзЗржб):** `docs/mnist_end_to_end_line_by_line_bn.md`

---

# 1) Imports тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
```

* `matplotlib.pyplot as plt` тЖТ рж░рзЗржЬрж╛рж▓рзНржЯ/ржЗржорзЗржЬ ржкрзНрж▓ржЯ ржХрж░рждрзЗред
* `torch` тЖТ ржЯрзЗржирж╕рж░, ржЕржЯрзЛ-ржЧрзНрж░рж╛ржб, ржбрж┐ржнрж╛ржЗрж╕ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯред
* `torch.nn as nn` тЖТ рж▓рзЗрзЯрж╛рж░/ржоржбрзЗрж▓/рж▓рж╕ ржХрзНрж▓рж╛рж╕ред
* `torch.optim as optim` тЖТ Adam/SGD ржЗрждрзНржпрж╛ржжрж┐ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрж╛рж░ред
* `DataLoader` тЖТ ржмрзНржпрж╛ржЪрзЗ ржбрзЗржЯрж╛ рж▓рзЛржбред
* `datasets`, `transforms` тЖТ рж░рзЗржбрж┐ржорзЗржб ржбрзЗржЯрж╛рж╕рзЗржЯ + ржкрзНрж░рж┐-ржкрзНрж░рж╕рзЗрж╕рж┐ржВред

---

# 2) Data Preprocessing тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
```

* `Compose([...])` тЖТ ржХрзЯрзЗржХржЯрж╛ ржЯрзНрж░рж╛ржирзНрж╕ржлрж░рзНржо ржХрзНрж░ржорж╛ржирзБрж╕рж╛рж░рзЗ ржЪрж╛рж▓рж╛рзЯред
* `ToTensor()` тЖТ PILтЖТTensor, ржкрж┐ржХрзНрж╕рзЗрж▓ `[0,1]` рж╕рзНржХрзЗрж▓рзЗред
* `Normalize(mean,std)` тЖТ `(x-mean)/std`; **MNIST mean=0.1307, std=0.3081**ред

```
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
```

* `root='./data'` тЖТ ржПржЦрж╛ржирзЗ ржбрзЗржЯрж╛ ржерж╛ржХржмрзЗред
* `train=True/False` тЖТ ржЯрзНрж░рзЗржи/ржЯрзЗрж╕рзНржЯ рж╕рзНржкрзНрж▓рж┐ржЯред
* `download=True` тЖТ ржирж╛ ржерж╛ржХрж▓рзЗ ржирж╛ржорж╛рзЯред
* `transform` тЖТ ржЙржкрж░рзЗрж░ ржкрзНрж░рж┐-ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржЕрзНржпрж╛ржкрзНрж▓рж╛ржЗред

```
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_dataset,  batch_size=1000, shuffle=False)
```

* `batch_size=64` (train) тЖТ рж╕рзНржерж┐рж░ ржЧрзНрж░рзЗржбрж┐рзЯрзЗржирзНржЯ + ржнрж╛рж▓рзЛ рж╕рзНржкрж┐ржбред
* `shuffle=True` (train) тЖТ ржЬрзЗржирж╛рж░рж╛рж▓рж╛ржЗржЬрзЗрж╢ржи ржнрж╛рж▓рзЛред
* `batch_size=1000` (test) тЖТ ржЗржнрзНржпрж╛рж▓рзБрзЯрзЗрж╢ржи ржжрзНрж░рзБржд; `shuffle=False` рж░рж╛ржЦрзЗред

> **ржЯрж┐ржЙржирж┐ржВ ржЯрж┐ржкрж╕:** ржмрзЬ GPU рж╣рж▓рзЗ train `batch_size` ржмрж╛рзЬрж╛рждрзЗ ржкрж╛рж░рзЛ; Windows/Notebook ржП `num_workers=0/2`, Linux/Colab ржП `num_workers=2тАУ8`, CUDA рж╣рж▓рзЗ `pin_memory=True`ред

---

# 3) Model тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
class DigitClassifier(nn.Module):
    def __init__(self):
        super(DigitClassifier, self).__init__()
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(28*28, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)  # 10 classes for digits 0тАУ9
```

* `nn.Module` рж╕рж╛ржмржХрзНрж▓рж╛рж╕ тЖТ ржХрж╛рж╕рзНржЯржо ржоржбрзЗрж▓ред
* `Flatten()` тЖТ `[N,1,28,28]` тЖТ `[N,784]`ред
* `Linear(784,128)` тЖТ ржкрзНрж░ржержо FC; 28├Ч28=784 **рж╣рж╛рж░рзНржб рж░рзБрж▓: Flatten ржХрж░рж╛ ржлрж┐ржЪрж╛рж░ = `in_features`**ред
* `ReLU()` тЖТ ржиржи-рж▓рж┐ржирж┐рзЯрж╛рж░рж┐ржЯрж┐; ржжрзНрж░рзБржд/рж╕рзНржЯрзЗржмрж▓ред
* `Linear(128,64)`, `Linear(64,10)` тЖТ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржлрж┐ржЪрж╛рж░ ржХржорзНржкрзНрж░рзЗрж╕ тЖТ рззрзж ржХрзНрж▓рж╛рж╕ logitsред

```
    def forward(self, x):
        x = self.flatten(x)        # [N,784]
        x = self.relu(self.fc1(x)) # [N,128]
        x = self.relu(self.fc2(x)) # [N,64]
        x = self.fc3(x)            # [N,10] (logits)
        return x  # CrossEntropyLoss ржирж┐ржЬрзЗржЗ softmax ржирзЗржмрзЗ
```

* **logits** рж░рж┐ржЯрж╛рж░рзНржи; ржЖрж▓рж╛ржжрж╛ Softmax ржжрзЗржмрзЗ ржирж╛ (CrossEntropyLoss ржирж┐ржЬрзЗрж░рж╛ ржирзЗрзЯ)ред

> **ржнрзНржпрж╛рж░рж┐рзЯрзЗрж╢ржи:** ржЗржиржкрзБржЯ рж╕рж╛ржЗржЬ ржмржжрж▓рж╛рж▓рзЗ `784` ржмржжрж▓рж╛рждрзЗ рж╣ржмрзЗ, ржиржЗрж▓рзЗ `LazyLinear`/CNN+GlobalPool ржирж╛ржУред

---

# 4) Device Setup тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

* GPU ржерж╛ржХрж▓рзЗ `"cuda"`, ржиржЗрж▓рзЗ `"cpu"`ред
* **Rule:** model, dataтАФржПржХржЗ deviceтАУржП ржерж╛ржХрждрзЗ рж╣ржмрзЗ (ржирж╛ рж╣рж▓рзЗ RuntimeError)ред

---

# 5) Model, Loss, Optimizer тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
model = DigitClassifier().to(device)
```

* ржоржбрзЗрж▓ ржбрж┐ржнрж╛ржЗрж╕рзЗ (GPU/CPU) ржкрж╛ржарж╛рж▓рж╛ржоред

```
criterion = nn.CrossEntropyLoss()
```

* ржорж╛рж▓рзНржЯрж┐-ржХрзНрж▓рж╛рж╕ ржХрзНрж▓рж╛рж╕рж┐ржлрж┐ржХрзЗрж╢ржи; **input=logits `[N,C]`**, **target=int `[N]`**ред
* ржЖрж▓рж╛ржжрж╛ softmax **ржжрзЗржмрзЗ ржирж╛**ред

```
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

* Adam: ржжрзНрж░рзБржд ржХржиржнрж╛рж░рзНржЬ; `lr=1e-3` ржнрж╛рж▓рзЛ рж╕рзНржЯрж╛рж░рзНржЯред
* ржмрзЬ `lr` тЖТ ржЕрж╕рзНржерж┐рж░/NaN; ржЫрзЛржЯ `lr` тЖТ рж╕рзНрж▓рзЛред

> **ржкрзНрж░рзЛ ржЯрж┐ржкрж╕:** `AdamW` + `weight_decay=1e-4` ржЖржзрзБржирж┐ржХ ржмрзЗрж╕рзНржЯ-ржкрзНрж░рзНржпрж╛ржХржЯрж┐рж╕; LR scheduler (Cosine/ReduceLROnPlateau) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж▓рзЗ ржЯрж┐ржЙржирж┐ржВ рж╕рж╣ржЬ рж╣рзЯред

---

# 6) Training Function тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
def train(model, device, train_loader, optimizer, criterion, epochs=5):
    model.train()
```

* **train mode**: Dropout on, BN ржмрзНржпрж╛ржЪ-рж╕рзНржЯрзНржпрж╛ржЯрж╕ ржЖржкржбрзЗржЯред

```
    for epoch in range(epochs):
        running_loss = 0.0
```

* ржЗржкржХ рж▓рзБржк + рж▓рж╕ ржХрж╛ржЙржирзНржЯрж╛рж░ред

```
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
```

* ржмрзНржпрж╛ржЪрзЗ ржбрзЗржЯрж╛/рж▓рзЗржмрзЗрж▓; deviceтАУржП ржкрж╛ржарж╛рж▓рж╛ржоред (ржорж┐рж╕ржорзНржпрж╛ржЪ=RuntimeError)

```
            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
```

* **ржЯрзНрж░рзЗржирж┐ржВ рзй ржзрж╛ржк**: zero\_grad тЖТ backward тЖТ step
* `outputs` logits `[N,10]`; `targets` int `[N]`ред

```
            running_loss += loss.item()
            if batch_idx % 100 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}")
```

* ржкрзНрж░рждрж┐ рззрзжрзж ржмрзНржпрж╛ржЪрзЗ ржкрзНрж░ржЧрзНрж░рзЗрж╕ рж▓ржЧ (ржбрзЗржЯрж╛ ржЫрзЛржЯ рж╣рж▓рзЗ 20/50 ржХрж░рж╛ ржпрж╛рзЯ)ред

```
        avg_loss = running_loss / len(train_loader)
        print(f"Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}")
```

* ржЗржкржХрзЗрж░ ржЧрзЬ ржЯрзНрж░рзЗржи рж▓рж╕тАФржХржорждрзЗ ржерж╛ржХрж╛ ржнрж╛рж▓рзЛ рж╕ржВржХрзЗрждред

> **рж░рж┐ржХржорзЗржирзНржбрзЗржб ржЕрзНржпрж╛ржб-ржЕржирж╕:** AMP (mixed precision), gradient clipping, LR scheduler, validation loop, early stoppingред

---

# 7) Testing Function тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
def test(model, device, test_loader):
    model.eval()
    correct = 0
    total = 0
```

* eval mode: Dropout off, BN рж╕рзНржерж┐рж░ред
* accuracy ржХрж╛ржЙржирзНржЯрж╛рж░ред

```
    with torch.no_grad():
        for data, targets in test_loader:
            data, targets = data.to(device), targets.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()
```

* `no_grad` тЖТ ржЧрзНрж░рзЗржбрж┐рзЯрзЗржирзНржЯ ржХрзНржпрж╛рж▓ржХрзБрж▓рзЗрж╢ржи ржмржирзНржз (ржорзЗржорж░рж┐/рж╕ржорзЯ рж╕рж╛рж╢рзНрж░рзЯ)ред
* `argmax(dim=1)` тЖТ predicted classред
* `total/correct` ржЖржкржбрзЗржЯред

```
    accuracy = 100 * correct / total
    print(f"Test Accuracy: {accuracy:.2f}%")
    return accuracy
```

* % ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐ рж░рж┐ржЯрж╛рж░рзНржи/ржкрзНрж░рж┐ржирзНржЯред

---

# 8) Prediction Visualization тАФ рж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
def visualize_predictions(model, device, test_loader, n=6):
    model.eval()
    data_iter = iter(test_loader)
    images, labels = next(data_iter)
    images, labels = images.to(device), labels.to(device)
```

* ржЯрзЗрж╕рзНржЯ ржерзЗржХрзЗ ржкрзНрж░ржержо ржмрзНржпрж╛ржЪ; deviceтАУржП ржкрж╛ржарж╛ржирзЛред
* `n` ржЫржмрж┐рж░ ржнрж┐ржЬрзБрзЯрж╛рж▓ (ржмрзНржпрж╛ржЪрзЗ `n`тАУржПрж░ ржХржо рж╣рж▓рзЗ ржЖржЧрзЗ `n=min(n, images.size(0))` ржХрж░рзЛ)ред

```
    outputs = model(images)
    _, preds = torch.max(outputs, 1)
```

* logitsтЖТpreds (ржХрзНрж▓рж╛рж╕ ржЗржиржбрзЗржХрзНрж╕)ред

```
    images = images.cpu()
    labels = labels.cpu()
    preds = preds.cpu()
```

* matplotlib CPU ржЯрзЗржирж╕рж░ рж▓рж╛ржЧрзЗ, рждрж╛ржЗ CPU-рждрзЗ ржЖржирж╛ред

```
    plt.figure(figsize=(12, 4))
    for i in range(n):
        plt.subplot(1, n, i+1)
        plt.imshow(images[i].squeeze(), cmap='gray')
        plt.title(f"True: {labels[i]}\nPred: {preds[i]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()
```

* 1├Чn ржЧрзНрж░рж┐ржбрзЗ ржЫржмрж┐; `squeeze()` тЖТ \[1,28,28]тЖТ\[28,28]ред
* `cmap='gray'` тЖТ ржЧрзНрж░рзЗрж╕рзНржХрзЗрж▓; RGB рж╣рж▓рзЗ ржмрж╛ржж ржжрж╛ржУред
* рж╢рж┐рж░рзЛржирж╛ржорзЗ рж╕рждрзНржп рж▓рзЗржмрзЗрж▓ ржУ ржкрзНрж░рзЗржбрж┐ржХрж╢ржиред

---

# 9) End-to-End рж░рж╛ржитАФрж▓рж╛ржЗржирзЗтАУрж▓рж╛ржЗржирзЗ

```
train(model, device, train_loader, optimizer, criterion, epochs=5)
```

* рзл ржЗржкржХ ржЯрзНрж░рзЗржирж┐ржВ; **epochs ржмрж╛рзЬрж╛рж▓рзЗ** ржмрзЗрж╢рж┐ рж╢рзЗржЦрзЗ (ржУржнрж╛рж░ржлрж┐ржЯрж┐ржВ рж╣рж▓рзЗ ржнрзНржпрж╛рж▓рж┐ржбрзЗрж╢ржи/ржЖрж░рзНрж▓рж┐-рж╕рзНржЯржкрж┐ржВ ржжрж░ржХрж╛рж░)ред

```
test(model, device, test_loader)
```

* ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯрзЗ ржлрж╛ржЗржирж╛рж▓ ржПржХрж┐ржЙрж░рзЗрж╕рж┐ред

```
visualize_predictions(model, device, test_loader)
```

* ржХрж┐ржЫрзБ рж╕рзНржпрж╛ржорзНржкрж▓рзЗрж░ ржкрзНрж░рзЗржбрж┐ржХрж╢ржи vs рж╕рждрзНржп рж▓рзЗржмрзЗрж▓ ржжрзЗржЦрж╛рзЯ (ржбрж┐ржмрж╛ржЧ/ржмрзЛржЭрж╛рж░ ржЬржирзНржп ржжрж╛рж░рзБржг)ред

---    


---

## 1) Imports (ржХрзА ржХрзЗржи)

1. `matplotlib.pyplot as plt` тАФ ржкрзНрж▓ржЯ/ржнрж┐ржЬрзБрзЯрж╛рж▓рж╛ржЗржЬрзЗрж╢ржи
2. `torch` тАФ ржЯрзЗржирж╕рж░, ржЕржЯрзЛ-ржЧрзНрж░рзНржпрж╛ржб, ржбрж┐ржнрж╛ржЗрж╕
3. `torch.nn as nn` тАФ рж▓рзЗрзЯрж╛рж░/ржоржбрзЗрж▓/рж▓рж╕ ржХрзНрж▓рж╛рж╕
4. `torch.optim as optim` тАФ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрж╛рж░ (Adam/SGD/тАж)
5. `DataLoader` тАФ ржмрзНржпрж╛ржЪрзЗ ржбрзЗржЯрж╛ рж▓рзЛржб
6. `datasets, transforms` тАФ рж░рзЗржбрж┐ржорзЗржб ржбрзЗржЯрж╛рж╕рзЗржЯ ржУ ржкрзНрж░рж┐-ржкрзНрж░рж╕рзЗрж╕рж┐ржВ

---

## 2) Data Processing

1. **Transforms (MNIST)**

   * `ToTensor()` тЖТ ржЗржорзЗржЬ тЖТ ржЯрзЗржирж╕рж░ \[0,1]
   * `Normalize((0.1307,), (0.3081,))` тЖТ рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржбрж╛ржЗржЬ
2. **Dataset**

   * `datasets.MNIST(..., train=True/False, download=True, transform=transform)`
3. **DataLoader**

   * Train: `batch_size=64`, `shuffle=True`
   * Test: `batch_size=1000`, `shuffle=False`
   * (ржРржЪрзНржЫрж┐ржХ) `num_workers` (Linux 2тАУ8), `pin_memory=True` (CUDA)

---

## 3) Model Architecture (MLP for MNIST)

1. ржЗржиржкрзБржЯ: \[N, 1, 28, 28] тЖТ `Flatten()` тЖТ \[N, **784**]
2. рж▓рзЗрзЯрж╛рж░: `Linear(784,128)` тЖТ `ReLU` тЖТ `Linear(128,64)` тЖТ `ReLU` тЖТ `Linear(64,10)`
3. ржЖржЙржЯржкрзБржЯ: **logits** \[N,10] (Softmax рж▓рж╕ ржлрж╛ржВрж╢ржиржЗ рж╣рзНржпрж╛ржирзНржбрзЗрж▓ ржХрж░рзЗ)

---

## 4) Device Setup

1. `device = torch.device("cuda" if torch.cuda.is_available() else "cpu")`
2. **рж░рзБрж▓:** model ржПржмржВ dataтАФ**ржПржХржЗ device** ржП ржерж╛ржХрждрзЗ рж╣ржмрзЗ

---

## 5) Model, Loss, Optimizer

1. `model = DigitClassifier().to(device)`
2. `criterion = nn.CrossEntropyLoss()` тАФ ржорж╛рж▓рзНржЯрж┐-ржХрзНрж▓рж╛рж╕; logits ржЗржиржкрзБржЯ
3. `optimizer = optim.Adam(model.parameters(), lr=1e-3)`

   * (ржкрзНрж░рзЛ) AdamW + `weight_decay=1e-4` ржмрзНржпржмрж╣рж╛рж░рзНржп

---

## 6) Training Loop тАФ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ (рж╕ржмрж╕ржорзЯ ржПржнрж╛ржмрзЗржЗ ржпрж╛ржмрзЗ)

1. **Mode set:** `model.train()`
2. **Batch loop:** `for data, targets in train_loader:`
3. **Device move:** `data, targets = data.to(device), targets.to(device)`
4. **Zero grads:** `optimizer.zero_grad()`
5. **Forward:** `outputs = model(data)`
6. **Loss:** `loss = criterion(outputs, targets)`
7. **Backward:** `loss.backward()`
8. **(Optional) Clip:** `torch.nn.utils.clip_grad_norm_(...)`
9. **Update:** `optimizer.step()`
10. **Log:** ржкрзНрж░рждрж┐ `log_interval` ржмрзНржпрж╛ржЪрзЗ рж▓рж╕ ржкрзНрж░рж┐ржирзНржЯ
11. **Epoch end:** `avg_train_loss = running_loss / len(train_loader)`
12. **(Recommended) Validation:** eval+no\_grad, val loss/acc
13. **(Optional) Scheduler:** `scheduler.step(val_loss)` / `scheduler.step()`
14. \*\*(Optional) Early stopping / Checkpoint save\`

---

## 7) Evaluation (Validation/Test) Loop тАФ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ

1. **Mode set:** `model.eval()`
2. **No grad:** `with torch.no_grad():`
3. **Batch loop:** `for data, targets in data_loader:`
4. **Device move:** `data, targets = data.to(device), targets.to(device)`
5. **Forward:** `outputs = model(data)`
6. **Loss (optional but good):** `loss = criterion(outputs, targets)` тЖТ `total_loss += loss.item()`
7. **Predictions:** `preds = outputs.argmax(dim=1)`
8. **Metrics:** `correct += (preds == targets).sum().item()`; `total += targets.size(0)`
9. **Aggregate:** `avg_loss = total_loss / len(data_loader)`; `accuracy = correct / total`
10. **Return/Log:** `avg_loss, accuracy`

---

## 8) Prediction Visualization тАФ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ

1. **Mode set:** `model.eval()`
2. **Get a batch:** `images, labels = next(iter(test_loader))`
3. **Device move:** `images, labels = images.to(device), labels.to(device)`
4. **Forward:** `outputs = model(images)`
5. **Predictions:** `preds = outputs.argmax(dim=1)`
6. **CPU for plotting:** `images, labels, preds = images.cpu(), labels.cpu(), preds.cpu()`
7. **Figure:** `plt.figure(figsize=(2*n, 3))`
8. **Loop 0..n-1:** `subplot тЖТ imshow(images[i].squeeze(), cmap='gray') тЖТ title(True/Pred) тЖТ axis off`
9. **Neat layout:** `plt.tight_layout(); plt.show()`

   * (ржЯрж┐ржк) `n = min(n, images.size(0))` ржжрж┐рзЯрзЗ ржЖржЙржЯ-ржЕржл-рж░рзЗржЮрзНржЬ ржПрзЬрж╛ржУ
   * RGB рж╣рж▓рзЗ `permute(1,2,0)`, `cmap` ржмрж╛ржж

---

## 9) End-to-End рж░рж╛ржи ржЕрж░рзНржбрж╛рж░

1. **Transforms рж╕рзЗржЯ** (train/test)
2. **Dataset рж▓рзЛржб** (`download=True`)
3. **DataLoader** (train: shuffle=True; test: shuffle=False)
4. **Device рж╕рж┐рж▓рзЗржХрзНржЯ**
5. **Model тЖТ device**, **Loss**, **Optimizer**
6. **Train (N epochs)** тЖТ avg train loss
7. **Test/Validation** тЖТ avg loss, accuracy
8. **Visualization** тЖТ ржХрж┐ржЫрзБ ржкрзНрж░рзЗржбрж┐ржХрж╢ржи ржкрзНрж▓ржЯ
9. **(Optional)** Scheduler / Early stopping / Checkpoint

---

## 10) ржЯрж┐ржЙржирж┐ржВ ржЪрж┐ржЯрж╢рж┐ржЯ

* **batch\_size** тЖС тЖТ ржжрзНрж░рзБржд/рж╕рзНржЯрзНржпрж╛ржмрж▓, RAM тЖС; тЖУ тЖТ ржзрзАрж░, ржХржЦржирзЛ ржЬрзЗржирж╛рж░рж╛рж▓рж╛ржЗржЬ тЖС
* **lr** тЖС тЖТ ржлрж╛рж╕рзНржЯ/ржЕрж╕рзНржерж┐рж░; тЖУ тЖТ рж╕рзНрж▓рзЛ/ржкрзНрж▓рзЗржЯрзЛ тЖТ Scheduler ржЗржЙржЬржлрзБрж▓
* **epochs** тЖС тЖТ рж╢рзЗржЦрж╛ тЖС/ржУржнрж╛рж░ржлрж┐ржЯ тЖС тЖТ Early stopping рж╕рж╣рж╛рзЯржХ
* **optimizer** тЖТ AdamW (рж╕рзНржЯрж╛рж░рзНржЯ), ржмрзЬ ржнрж┐рж╢ржирзЗ SGD+momentum + cosine/step LR
* **regularization** тЖТ weight decay, dropout, data augmentation
* **perf** тЖТ Linux ржП `num_workers` ржмрж╛рзЬрж╛ржУ; CUDA рж╣рж▓рзЗ `pin_memory=True`; AMP ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЛ

---

ржПржЯрж╛ржЗ **рж╕рж┐рж░рж┐рзЯрж╛рж▓-ржУрзЯрж╛ржЗржЬ ржлрзБрж▓ рж╕рж╛ржорж╛рж░рж┐**тАФImports тЖТ Data тЖТ Model тЖТ Device тЖТ Loss/Opt тЖТ Train тЖТ Eval тЖТ Viz тЖТ Run тЖТ Tuningред


